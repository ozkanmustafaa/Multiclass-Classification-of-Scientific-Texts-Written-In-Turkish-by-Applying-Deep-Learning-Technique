# MSc thesis study of Mustafa Ozkan in Feb 2022
The BERT deep learning technique, which is developed by Google in October 2018, has become very popular in the world of machine learning and natural language processing. BERT, which stands for Bidirectional Encoder Representations of Transformers, can be explained as a natural language processing technique that uses artificial intelligence and machine learning technologies together. Nowadays, classification problems that are part of the supervised learning methodology are frequently encountered. Classification is based on the ability of a trained machine to predict and classify new data. The purpose is to distribute data between classes defined on a dataset. In Turkish many of the difficulties arise from being an agglutinative language and having a rich but complex morphology. These difficulties cause hard to solving multiclass classification problems. However, it has become more easily solvable with using BERT deep learning technique. We used academic research and scientific studies written in Turkish in the last 10 years as our dataset. We fine-tuned our dataset on a pre-trained Turkish BERT model by applying BERT deep learning technique to use in multiclass classification problems. As a result of experiments, it is seen that the accuracy of the system we have trained has achieved 96% accuracy.
